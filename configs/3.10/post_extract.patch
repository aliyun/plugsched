diff --git a/kernel/sched/mod/Makefile b/kernel/sched/mod/Makefile
index 38dbf6d..31c6d91 100644
--- a/kernel/sched/mod/Makefile
+++ b/kernel/sched/mod/Makefile
@@ -15,9 +15,9 @@ CFLAGS_core.o := $(PROFILING) -fno-omit-frame-pointer
 endif
 
 objs-y += core.o
-objs-y += idle.o fair.o rt.o deadline.o
+objs-y += idle_task.o fair.o rt.o deadline.o
 
-objs-$(CONFIG_SMP) += cpupri.o cpudeadline.o topology.o stop_task.o pelt.o
+objs-$(CONFIG_SMP) += cpupri.o cpudeadline.o stop_task.o
 objs-$(CONFIG_SCHEDSTATS) += stats.o
 objs-$(CONFIG_SCHED_DEBUG) += debug.o
 
diff --git a/kernel/sched/mod/core.c b/kernel/sched/mod/core.c
index e5236bd..1970dcf 100644
--- a/kernel/sched/mod/core.c
+++ b/kernel/sched/mod/core.c
@@ -57,6 +57,9 @@
 #include <linux/proc_fs.h>
 #include <linux/seq_file.h>
 #include <linux/sysctl.h>
+
+#undef CONFIG_FTRACE_SYSCALLS
+
 #include <linux/syscalls.h>
 #include <linux/times.h>
 #include <linux/tsacct_kern.h>
@@ -89,7 +92,6 @@
 #include "../../workqueue_internal.h"
 #include "../../smpboot.h"
 
-#define CREATE_TRACE_POINTS
 #include <trace/events/sched.h>
 
 #ifdef smp_mb__before_atomic
@@ -7530,9 +7532,13 @@ void sched_cpu_deactivate(unsigned int cpu);
 #else
 #endif /* CONFIG_SMP */
 
+extern char __module_sched_start[], __module_sched_end[];
+
 int in_sched_functions(unsigned long addr)
 {
 	return in_lock_functions(addr) ||
+		(addr >= (unsigned long)__module_sched_start
+		&& addr < (unsigned long)__module_sched_end) ||
 		(addr >= (unsigned long)__sched_text_start
 		&& addr < (unsigned long)__sched_text_end);
 }
diff --git a/kernel/sched/mod/main.c b/kernel/sched/mod/main.c
index 8e08642..c1d1604 100644
--- a/kernel/sched/mod/main.c
+++ b/kernel/sched/mod/main.c
@@ -12,19 +12,30 @@
 #include <linux/sched/task.h>
 #include <linux/sysfs.h>
 #include <linux/version.h>
+#include <linux/debugfs.h>
+#include <linux/proc_fs.h>
 #include "sched.h"
 #include "helper.h"
 #include "mempool.h"
 #include "head_jump.h"
 #include "stack_check.h"
 
-#define CHECK_STACK_LAYOUT() \
-	BUILD_BUG_ON_MSG(MODULE_FRAME_POINTER != VMLINUX_FRAME_POINTER, \
-		"stack layout of __schedule can not match to it in vmlinux")
-
 #define MAX_CPU_NR		1024
 
-extern void __orig___schedule(bool);
+#define smp_cond_load_relaxed(ptr, cond_expr) ({		\
+	typeof(ptr) __PTR = (ptr);			      \
+	typeof(*ptr) VAL;					\
+	for (;;) {					      \
+		VAL = READ_ONCE(*__PTR);			\
+		if (cond_expr)				  \
+			break;				  \
+		cpu_relax();				    \
+	}							\
+	VAL;						    \
+})
+#define atomic_cond_read_relaxed(v, c) smp_cond_load_relaxed(&(v)->counter, (c))
+
+extern void __orig___schedule(void);
 int process_id[MAX_CPU_NR];
 atomic_t cpu_finished;
 atomic_t clear_finished;
@@ -53,10 +64,9 @@ extern struct percpu_rw_semaphore cpuset_rwsem;
 	percpu_up_write(&cpuset_rwsem)
 #endif
 
-extern cpumask_var_t sd_sysctl_cpus;
 extern const struct file_operations __mod_sched_feat_fops;
-extern const struct seq_operations __mod_sched_debug_sops;
-extern const struct seq_operations __mod_schedstat_sops;
+extern const struct file_operations __mod_sched_debug_fops;
+extern const struct file_operations __mod_proc_schedstat_operations;
 
 static struct dentry *sched_features_dir;
 static s64 stop_time;
@@ -265,8 +275,25 @@ static int sync_sched_mod(void *func)
 }
 
 #ifdef CONFIG_SCHED_DEBUG
+extern void __mod_register_sched_domain_sysctl(void);
+extern void __mod_unregister_sched_domain_sysctl(void);
+
+extern struct ctl_table_header *__orig_sd_sysctl_header;
+extern struct ctl_table __orig_sd_ctl_dir[];
+extern void __orig_sd_free_ctl_entry(struct ctl_table **tablep);
+
 extern void __orig_register_sched_domain_sysctl(void);
-extern void __orig_unregister_sched_domain_sysctl(void);
+static void __orig_unregister_sched_domain_sysctl(void)
+{
+	if (__orig_sd_sysctl_header)
+		unregister_sysctl_table(__orig_sd_sysctl_header);
+
+	__orig_sd_sysctl_header = NULL;
+
+	if (__orig_sd_ctl_dir[0].child)
+		__orig_sd_free_ctl_entry(&__orig_sd_ctl_dir[0].child);
+}
+/* DON'T MODIFY INLINE EXTERNAL FUNCTION unregister_sched_domain_sysctl */
 
 static inline void install_sched_domain_sysctl(void)
 {
@@ -274,7 +301,7 @@ static inline void install_sched_domain_sysctl(void)
 	plugsched_cpuset_lock();
 
 	__orig_unregister_sched_domain_sysctl();
-	register_sched_domain_sysctl();
+	__mod_register_sched_domain_sysctl();
 
 	plugsched_cpuset_unlock();
 	mutex_unlock(&cgroup_mutex);
@@ -285,8 +312,7 @@ static inline void restore_sched_domain_sysctl(void)
 	mutex_lock(&cgroup_mutex);
 	plugsched_cpuset_lock();
 
-	unregister_sched_domain_sysctl();
-	cpumask_copy(sd_sysctl_cpus, cpu_possible_mask);
+	__mod_unregister_sched_domain_sysctl();
 	__orig_register_sched_domain_sysctl();
 
 	plugsched_cpuset_unlock();
@@ -312,7 +338,7 @@ void install_sched_debugfs(void)
 }
 
 extern struct file_operations __orig_sched_feat_fops;
-extern struct seq_operations  __orig_sched_debug_sops;
+extern struct file_operations __orig_sched_debug_fops;
 
 void restore_sched_debugfs(void)
 {
@@ -325,7 +351,7 @@ int install_sched_debug_procfs(void)
 {
 	remove_proc_entry("sched_debug", NULL);
 
-	if (!proc_create_seq("sched_debug", 0444, NULL, &__mod_sched_debug_sops))
+	if (!proc_create("sched_debug", 0444, NULL, &__mod_sched_debug_fops))
 		return -ENOMEM;
 
 	return 0;
@@ -335,7 +361,7 @@ int restore_sched_debug_procfs(void)
 {
 	remove_proc_entry("sched_debug", NULL);
 
-	if (!proc_create_seq("sched_debug", 0444, NULL, &__orig_sched_debug_sops))
+	if (!proc_create("sched_debug", 0444, NULL, &__orig_sched_debug_fops))
 		return -ENOMEM;
 
 	return 0;
@@ -343,14 +369,14 @@ int restore_sched_debug_procfs(void)
 #endif
 
 #ifdef CONFIG_SCHEDSTATS
-extern struct seq_operations __orig_schedstat_sops;
+extern struct file_operations __orig_proc_schedstat_operations;
 
 /* schedstat interface in proc */
 int install_proc_schedstat(void)
 {
 	remove_proc_entry("schedstat", NULL);
 
-	if (!proc_create_seq("schedstat", 0444, NULL, &__mod_schedstat_sops))
+	if (!proc_create("schedstat", 0444, NULL, &__mod_proc_schedstat_operations))
 		return -ENOMEM;
 
 	return 0;
@@ -360,7 +386,7 @@ int restore_proc_schedstat(void)
 {
 	remove_proc_entry("schedstat", NULL);
 
-	if (!proc_create_seq("schedstat", 0444, NULL, &__orig_schedstat_sops))
+	if (!proc_create("schedstat", 0444, NULL, &__orig_proc_schedstat_operations))
 		return -ENOMEM;
 
 	return 0;
@@ -586,8 +612,6 @@ static int __init sched_mod_init(void)
 {
 	int ret;
 
-	CHECK_STACK_LAYOUT();
-
 	printk("Hi, scheduler mod is installing!\n");
 	init_start = ktime_get();
 
diff --git a/kernel/sched/mod/sched_rebuild.c b/kernel/sched/mod/sched_rebuild.c
index 20e8f4c..d2b3343 100644
--- a/kernel/sched/mod/sched_rebuild.c
+++ b/kernel/sched/mod/sched_rebuild.c
@@ -8,8 +8,6 @@
 #include "sched.h"
 #include "helper.h"
 
-extern void __orig_set_rq_offline(struct rq*);
-extern void __orig_set_rq_online(struct rq*);
 extern unsigned int process_id[];
 
 extern struct sched_class __orig_stop_sched_class;
@@ -44,12 +42,47 @@ DEFINE_PER_CPU(struct list_head, dying_task_list);
 #define NR_SCHED_CLASS 5
 struct sched_class bak_class[NR_SCHED_CLASS];
 
+extern void __mod_set_rq_offline(struct rq*);
+extern void __mod_set_rq_online(struct rq*);
+
+static void __orig_set_rq_online(struct rq *rq)
+{
+	if (!rq->online) {
+		const struct sched_class *class;
+
+		cpumask_set_cpu(rq->cpu, rq->rd->online);
+		rq->online = 1;
+
+		for_each_class(class) {
+			if (class->rq_online)
+				class->rq_online(rq);
+		}
+	}
+}
+/* DON'T MODIFY INLINE EXTERNAL FUNCTION __orig_set_rq_online */
+
+static void __orig_set_rq_offline(struct rq *rq)
+{
+	if (rq->online) {
+		const struct sched_class *class;
+
+		for_each_class(class) {
+			if (class->rq_offline)
+				class->rq_offline(rq);
+		}
+
+		cpumask_clear_cpu(rq->cpu, rq->rd->online);
+		rq->online = 0;
+	}
+}
+/* DON'T MODIFY INLINE EXTERNAL FUNCTION __orig_set_rq_offline */
+
 #if LINUX_VERSION_CODE < KERNEL_VERSION(5, 3, 0)
 
 extern struct task_struct __orig_fake_task;
 
 #define pick_next_task_rq(class, rf) \
-	(class)->pick_next_task(rq, &__orig_fake_task, &(rf))
+	(class)->pick_next_task(rq, &__orig_fake_task)
 
 #else
 #define pick_next_task_rq(class, rf) \
@@ -83,15 +116,14 @@ void clear_sched_state(bool mod)
 {
 	struct task_struct *g, *p;
 	struct rq *rq = this_rq();
-	struct rq_flags rf;
-	int queue_flags = DEQUEUE_SAVE | DEQUEUE_MOVE | DEQUEUE_NOCLOCK;
+	int queue_flags = DEQUEUE_SAVE;
 	int cpu = smp_processor_id();
 
-	rq_lock(rq, &rf);
+	raw_spin_lock(&rq->lock);
 
 	if (mod) {
 		update_rq_clock(rq);
-		set_rq_offline(rq);
+		__mod_set_rq_offline(rq);
 	} else {
 		__orig_update_rq_clock(rq);
 		__orig_set_rq_offline(rq);
@@ -120,7 +152,7 @@ void clear_sched_state(bool mod)
 			break;
 
 		for_each_class(class) {
-			next = pick_next_task_rq(class, rf);
+			next = pick_next_task_rq(class, NULL);
 			if (next) {
 				next->sched_class->put_prev_task(rq, next);
 				next->sched_class->dequeue_task(rq, p, queue_flags);
@@ -129,7 +161,7 @@ void clear_sched_state(bool mod)
 			}
 		}
 	}
-	rq_unlock(rq, &rf);
+	raw_spin_unlock(&rq->lock);
 }
 
 void rebuild_sched_state(bool mod)
@@ -137,15 +169,14 @@ void rebuild_sched_state(bool mod)
 	struct task_struct *g, *p;
 	struct task_group *tg;
 	struct rq *rq = this_rq();
-	struct rq_flags rf;
-	int queue_flags = ENQUEUE_RESTORE | ENQUEUE_MOVE | ENQUEUE_NOCLOCK;
+	int queue_flags = ENQUEUE_RESTORE;
 	int cpu = smp_processor_id();
 
-	rq_lock(rq, &rf);
+	raw_spin_lock(&rq->lock);
 
 	if (mod) {
 		update_rq_clock(rq);
-		set_rq_online(rq);
+		__mod_set_rq_online(rq);
 	} else {
 		__orig_update_rq_clock(rq);
 		__orig_set_rq_online(rq);
@@ -166,7 +197,7 @@ void rebuild_sched_state(bool mod)
 		p->sched_class->enqueue_task(rq, p, queue_flags);
 		list_del_init(&p->tasks);
 	}
-	rq_unlock(rq, &rf);
+	raw_spin_unlock(&rq->lock);
 
 	if (process_id[cpu])
 		return;
@@ -176,12 +207,12 @@ void rebuild_sched_state(bool mod)
 		if (tg == &root_task_group)
 			continue;
 
-		if (tg->cfs_bandwidth.period_active) {
+		if (hrtimer_active(&tg->cfs_bandwidth.period_timer)) {
 			hrtimer_restart(&tg->cfs_bandwidth.period_timer);
 			hrtimer_restart(&tg->cfs_bandwidth.slack_timer);
 		}
 #ifdef CONFIG_RT_GROUP_SCHED
-		if (tg->rt_bandwidth.rt_period_active)
+		if (hrtimer_active(&tg->rt_bandwidth.rt_period_timer))
 			hrtimer_restart(&tg->rt_bandwidth.rt_period_timer);
 #endif
 	}
diff --git a/kernel/sched/mod/stack_check.h b/kernel/sched/mod/stack_check.h
index f83c463..2517230 100644
--- a/kernel/sched/mod/stack_check.h
+++ b/kernel/sched/mod/stack_check.h
@@ -24,7 +24,6 @@ static void stack_check_init(void)
 	#undef EXPORT_PLUGSCHED
 	#undef EXPORT_CALLBACK
 
-	vm_func_size[NR___schedule] = 0;
 	addr_sort(vm_func_addr, vm_func_size, NR_INTERFACE_FN);
 
 	#define EXPORT_CALLBACK(fn, ...) 				\
@@ -41,7 +40,6 @@ static void stack_check_init(void)
 	#undef EXPORT_PLUGSCHED
 	#undef EXPORT_CALLBACK
 
-	mod_func_size[NR___schedule] = 0;
 	addr_sort(mod_func_addr, mod_func_size, NR_INTERFACE_FN);
 }
 
@@ -143,11 +141,7 @@ static unsigned int get_stack_trace(struct task_struct *tsk,
         trace.max_entries = MAX_STACK_ENTRIES;
         trace.entries = store;
 
-	if (!try_get_task_stack(tsk))
-		return 0;
-
 	save_stack(&trace, tsk);
-	put_task_stack(tsk);
 	return trace.nr_entries;
 }
 #endif
